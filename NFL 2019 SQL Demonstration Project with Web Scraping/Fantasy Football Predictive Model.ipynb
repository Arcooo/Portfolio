{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href>https://www.lineups.com/nfl/roster/new-england-patriots</a>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my imports\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# NOTES while coding\n",
    "# imports I tried\n",
    "# from lxml.html.clean import clean_html\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# the location of a webdriver on my computer\n",
    "# this thing is probably what I need if I want to extract from complex websites where forms, and buttons, and parameters\n",
    "# need to be changed on the website.\n",
    "# driver = webdriver.Chrome('C:/NEW PROGRAMS/chromedriver_win32/chromedriver.exe')\n",
    "\n",
    "# if I wanted to replace a certain letter in a string\n",
    "# and how to make things lowercase\n",
    "# for i, playerName in enumerate(players):\n",
    "# #     replace spaces with a dash and make name lowercase\n",
    "#     players[i] = players[i].replace(\" \", \"-\").lower()\n",
    "\n",
    "# An example of what a x --\n",
    "# /html/body/app-root/app-nfl/app-roster/div/div/div[2]/div[2]/div/div/table/tbody/tr[1] -- xpat code from a website\n",
    "# looks like\n",
    "\n",
    "# get the current date and time\n",
    "# current_time = datetime.datetime.now()\n",
    "\n",
    "# enumerated for loop\n",
    "# for i, player in enumerate(playerData):\n",
    "#     print (i, player)\n",
    "\n",
    "# a nooby way to get rid of spaces and enters\n",
    "# for each in playerInfo[0].text_content():\n",
    "#     if(each != ' ' and each != '\\n'):\n",
    "#         print(each)\n",
    "\n",
    "# URL \n",
    "# baseURL = \"https://www.lineups.com/nfl/player-stats/\"\n",
    "# tempUrl = baseURL + players[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body bgcolor=\"white\">\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr/><center>nginx/1.14.1</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first you have the URL of the site you want to webscrape from.\n",
    "url = \"https://www.lineups.com/nfl/roster/new-england-patriots\"\n",
    "# then you send a get request for the web html document and that comes back to you as a string\n",
    "page = requests.get(url).text\n",
    "# and then it turns that string into html formatted Python print and Tag-attached code. \n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "# print(soup) # see soup\n",
    "\n",
    "# I now have the document on my computer to be picked clean of what I need.\n",
    "# NFL 2018-2019 Data extraction to be used in Excel. Will also need pandas Dataframe for transition from code to excel.\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a3603166a7cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mheadersInfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'thead'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadersInfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mheaderCols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheadersInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "# Get headers\n",
    "headersInfo = soup.find('thead')\n",
    "print(headersInfo)\n",
    "headerCols = headersInfo.findAll('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'findAll'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-02390d4004c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get headers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mheadersInfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'thead'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mheaderCols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheadersInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# so what I am doing here is naming a variable headersInfo to find the first @thead in the document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'findAll'"
     ]
    }
   ],
   "source": [
    "# Get headers\n",
    "headersInfo = soup.find('thead')\n",
    "headerCols = headersInfo.findAll('a')\n",
    "\n",
    "# so what I am doing here is naming a variable headersInfo to find the first @thead in the document\n",
    "# In this particular table, in thead, the first @a in the document numerically in the code after the html element @thead \n",
    "# is the info we need. The @a tagged elements need to be clicked in the original document so that you are able to sort by \n",
    "# relevance. \n",
    "\n",
    "# next we .findAll the a elements in the \"new\" document because thats the tag we need.\n",
    "# now that we have a -list of all the table data we need for our excel file of NFL data,\n",
    "# we need to GET THE TEXT FOR THE HEADERS AND SAVE IT IN THE TOP OF THE DATAFRAME I NEED TO USE\n",
    "\n",
    "headerColList = []\n",
    "for i,headerCol in enumerate(headerCols):\n",
    "#     print(headerCols[i].text.strip()) # to see the headerCols in good format\n",
    "    headerColList.append(headerCols[i].text.strip())\n",
    "    \n",
    "# print(headerColList) # The header for the dataframe for excel\n",
    "\n",
    "# I am getting the team data for the 2019-20 season. \n",
    "# I can see some upcoming problems. \n",
    "# I am going to have to figure out how to use chromeDriver or another way to switch the html buttons \n",
    "# Also, I would also like to put player stats data for the 2018-2019 season which happened last year. The stats are set\n",
    "# up to present the 2018-2019 season while the team is set up for the current year which hasn't started yet.\n",
    "# This means that the tables won't match up exactly, which is ok. Some of the players won't have any data in the beginning.\n",
    "# Well if there is a difference than that means they were around the year before, so players without data are new. \n",
    "\n",
    "# ok now I need to get my actual player data of the 2019-2020 roster without stats, just info = PlayerInformationTable\n",
    "# The code below finds the first tbody element in the soup document which is what we need for the data\n",
    "PlayerRosterInfoData = soup.find('tbody')\n",
    "\n",
    "# Make a list of all the 'tr' rows which are each individual players info\n",
    "t_content_rows = PlayerRosterInfoData.findAll('tr',{'class':'t-content'})\n",
    "# print(len(t_content_rows)) # number of players in table\n",
    "\n",
    "playerData = []\n",
    "\n",
    "# for each player\n",
    "for i,each_player in enumerate(t_content_rows):\n",
    "#     get all the column info for each found in the @td tag\n",
    "    player_row = each_player.findAll('td')\n",
    "    \n",
    "    \n",
    "    tempData = []\n",
    "    \n",
    "    \n",
    "#     each td contains info for the dataframe\n",
    "#     for i,col in enumerate(player_row):\n",
    "# #       the players name at indices 1 needs to be formated correctly\n",
    "#         if (i!=1):\n",
    "# #             print(col.text.strip())\n",
    "#             tempData.append(col.text.strip())\n",
    "#         else:\n",
    "#             playerName_re = re.compile('[a-zA-Z]+\\s[a-zA-Z]+')        \n",
    "#             print(playerName_re.match(col.text.strip()).group())\n",
    "    print(tempData)\n",
    "\n",
    "\n",
    "\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]], columns = headerColList)\n",
    "print(df)\n",
    "\n",
    "# df = pd.DataFrame([], columns = headerColList)\n",
    "\n",
    "# df.append(headerColList)\n",
    "# print(df)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = html.fromstring(page.content)\n",
    "\n",
    "# playerInfo = tree.xpath('//tbody') \n",
    "# # print(playerInfo[0].text_content()[0:100])\n",
    "\n",
    "# for each in playerInfo[0].text_content():\n",
    "#     if(each != ' ' and each != '\\n'):\n",
    "#         print(each)\n",
    "\n",
    "# print(type(playerInfo[0].text_content()))\n",
    "\n",
    "\n",
    "# print(playerInfo[0].xpath('//td')[0])\n",
    "\n",
    "# players = tree.xpath('//span[@class = \"player-name-col-lg\"]/text()')\n",
    "\n",
    "\n",
    "# for i, playerName in enumerate(players):\n",
    "# #     replace spaces with a dash and make name lowercase\n",
    "#     players[i] = players[i].replace(\" \", \"-\").lower()\n",
    "\n",
    "# print(players[0])\n",
    "\n",
    "# baseURL = \"https://www.lineups.com/nfl/player-stats/\"\n",
    "# tempUrl = baseURL + players[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(tempUrl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
