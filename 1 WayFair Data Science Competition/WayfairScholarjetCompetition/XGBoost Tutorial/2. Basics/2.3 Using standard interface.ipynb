{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:06] 6513x127 matrix with 143286 entries loaded from ../data/agaricus.txt.train\n",
      "[15:28:06] 1611x127 matrix with 35442 entries loaded from ../data/agaricus.txt.test\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix('../data/agaricus.txt.train')\n",
    "dtest = xgb.DMatrix('../data/agaricus.txt.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtrain.get_label())\n",
    "dtrain.get_weight()\n",
    "# for i, row in enumerate(dtrain.get_label()):\n",
    "#     print (i, row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 6513 rows and 127 columns\n",
      "Test dataset contains 1611 rows and 127 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset contains {0} rows and {1} columns\".format(dtrain.num_row(), dtrain.num_col()))\n",
    "print(\"Test dataset contains {0} rows and {1} columns\".format(dtest.num_row(), dtest.num_col()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train possible labels: \n",
      "[0. 1.]\n",
      "\n",
      "Test possible labels: \n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train possible labels: \")\n",
    "print(np.unique(dtrain.get_label()))\n",
    "\n",
    "print(\"\\nTest possible labels: \")\n",
    "print(np.unique(dtest.get_label()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':2,\n",
    "    'silent':1,\n",
    "    'eta':1\n",
    "}\n",
    "\n",
    "num_rounds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-error:0.042831\ttrain-error:0.046522\n",
      "[1]\ttest-error:0.021726\ttrain-error:0.022263\n",
      "[2]\ttest-error:0.006207\ttrain-error:0.007063\n",
      "[3]\ttest-error:0.018001\ttrain-error:0.0152\n",
      "[4]\ttest-error:0.006207\ttrain-error:0.007063\n"
     ]
    }
   ],
   "source": [
    "watchlist  = [(dtest,'test'), (dtrain,'train')] # native interface only\n",
    "bst = xgb.train(params, dtrain, num_rounds, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08073306, 0.92217326, 0.08073306, ..., 0.98059034, 0.01182149,\n",
       "       0.98059034], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_prob = bst.predict(dtest)\n",
    "preds_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate simple accuracy metric to verify the results. Of course validation should be performed accordingly to the dataset, but in this case accuracy is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 1601/1611\n",
      "Error: 0.0062\n"
     ]
    }
   ],
   "source": [
    "labels = dtest.get_label()\n",
    "preds = preds_prob > 0.5 # threshold\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if (labels[i] == preds[i]):\n",
    "        correct += 1\n",
    "\n",
    "print('Predicted correctly: {0}/{1}'.format(correct, len(preds)))\n",
    "print('Error: {0:.4f}'.format(1-correct/len(preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
