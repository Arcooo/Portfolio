{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing/Cleaning Class</h1>\n",
    "\n",
    "\n",
    "\n",
    "0. Pre functions\n",
    "1. Missing Data\n",
    "2. Irrelevant Data\n",
    "3. Reducing\n",
    "4. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd  # Dataframes\n",
    "import numpy as np  # arrays\n",
    "import matplotlib.pyplot as plt  # plotting visuals\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    '''\n",
    "    Initiation, log, get, and functions\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.df = -1  # main dataframe\n",
    "        self.log = []  # class log list\n",
    "        self.logCount = 0  # used for debugging\n",
    "    \n",
    "    # Log class actions\n",
    "    def logit(self, logString):\n",
    "        s = \"LOG:\" + str(self.logCount) + \" \"\n",
    "        s += (logString)\n",
    "        self.log.append(s)\n",
    "        self.logCount += 1   \n",
    "    \n",
    "    # Get global DataFrame\n",
    "    def getDf(self):\n",
    "        return self.df\n",
    "    \n",
    "    # Get global log\n",
    "    def getLog(self):\n",
    "        return self.log\n",
    "    \n",
    "    def printLog(self):\n",
    "        self.printList(self.log)\n",
    "    \n",
    "    # Print a list object with x amount of columns, default=1\n",
    "    def printList(self, objList):\n",
    "        for i, each in enumerate(objList):\n",
    "            print(each)\n",
    "    \n",
    "    '''\n",
    "    Import Data\n",
    "    '''\n",
    "    # Imports file into a pandas dataframe\n",
    "    def dataImport(self, filename):\n",
    "        # Class log block\n",
    "        if (type(self.df) == pd.DataFrame): \n",
    "            self.logit(\"dataImport- Overwritting class data\")\n",
    "        else: \n",
    "            self.logit(\"dataImport- Importing file\")\n",
    "        \n",
    "        # Pandas csv data import\n",
    "        try:\n",
    "            self.df = pd.read_csv(filename, index_col=0)\n",
    "        except:\n",
    "            pass    \n",
    "        return self.df\n",
    "    \n",
    "    '''\n",
    "    Data Cleaning Functions\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    pureMean function takes the predictor variable as the parameter\n",
    "    \n",
    "    '''\n",
    "    def pureMean(self, predictionCol, printf=False):\n",
    "        # make a boolean Series for data above 0\n",
    "        buyersDf = self.df[predictionCol] > 0\n",
    "\n",
    "        # create DataFrame from series of all those above 0\n",
    "        buyersDf = self.df[buyersDf]\n",
    "\n",
    "        # mean of a random population        \n",
    "        pureMean = len(buyersDf) / len(self.df)\n",
    "        \n",
    "        # sum of the predictor column \n",
    "        predictorSum = buyersDf[predictionCol].sum().round(2)\n",
    "        \n",
    "        # of those above 0, average\n",
    "        avgPredictorSum = predictorSum / len(buyersDf)\n",
    "        \n",
    "        # spread out sum over entire population\n",
    "        populationAveragePredictor = predictorSum / len(self.df)\n",
    "        \n",
    "        if (printf):\n",
    "            print(\"Pure Mean:\", \"{:.2%}\".format(pureMean))\n",
    "            print(\"Sum of-\", predictionCol, \": ${:,.2f}\".format(predictorSum))\n",
    "            print(\"Average of-\", predictionCol, \": ${:.2f}\".format(avgPredictorSum))\n",
    "            print(\"Population Average of-\", predictionCol, \": ${:.2f}\".format(populationAveragePredictor))\n",
    "        \n",
    "        \n",
    "        return pureMean, predictorSum, avgPredictorSum, populationAveragePredictor\n",
    "\n",
    "    \n",
    "    # prints the number of NaN rows in each column\n",
    "    def NanCounts(self):\n",
    "        nanDict = {}\n",
    "        for col in self.df:\n",
    "            s = self.df[col].value_counts(dropna = False)\n",
    "            if (float('nan') in s):\n",
    "                print(col, s.get(float('nan')))\n",
    "    \n",
    "    def fillNans(self, col):\n",
    "        self.df.fillna(-999, inplace = True)\n",
    "        \n",
    "\n",
    "    def oneHotEncoding(self):\n",
    "        # Initialize new output DataFrame\n",
    "        output = pd.DataFrame(index = self.df.index)\n",
    "\n",
    "#         # Investigate each feature column for the data\n",
    "        for col, col_data in self.df.iteritems():\n",
    "\n",
    "#             # If data type is categorical, convert to dummy variables\n",
    "            if col_data.dtype == object:\n",
    "                col_data = pd.get_dummies(col_data, prefix = col)\n",
    "\n",
    "#             # Collect the revised columns\n",
    "            output = output.join(col_data)\n",
    "        return output   \n",
    "\n",
    "    \n",
    "\n",
    "# pre = Preprocessing()\n",
    "# pre.dataImport('Training and Holdout Data/small.csv')\n",
    "# pre.NanCounts()\n",
    "# pre.oneHotEncoding()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0 Pre Functions</h3>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numorderone 2295\n",
      "numorderthreeone 2295\n",
      "numorderseventhree 2295\n",
      "numorderthirtyseven 2295\n",
      "numordersixtythirty 2295\n",
      "numorderyearsixty 2295\n",
      "sumrevone 2295\n",
      "sumrevthreeone 2295\n",
      "sumrevseventhree 2295\n",
      "sumrevthirtyseven 2296\n",
      "sumrevsixtythirty 2296\n",
      "sumrevyearsixty 2295\n",
      "numbamorder 2295\n",
      "numselforder 2295\n",
      "totalrev 2297\n",
      "aov 2297\n",
      "cuidshare 2295\n",
      "numstores 2295\n",
      "pospercentage 2297\n",
      "numinf 2297\n",
      "numinfconnect 2297\n",
      "numinfphone 2297\n",
      "numinfquote 2297\n",
      "percentlarge 2295\n",
      "percdirtythirty 2295\n",
      "percdirtyninetythirty 2295\n",
      "percdirtyyearninety 2295\n",
      "numbilling 3054\n",
      "numreturn 3054\n",
      "numwims 3054\n",
      "numproblem 3054\n",
      "numother 3054\n",
      "percentresolved 3054\n",
      "minnps 3168\n",
      "avgnps 3168\n",
      "maxnps 3168\n",
      "nps_count 3168\n",
      "numquote 3199\n",
      "numorderfromquote 3199\n",
      "quoteconrate 3199\n",
      "avgquoteprice 3199\n",
      "avgconquoteprice 3297\n",
      "numvisitone 127\n",
      "numvisitthreeone 127\n",
      "numvisitseventhree 127\n",
      "numvisitthirtyseven 127\n",
      "numvisitsixtythirty 127\n",
      "numvisityearsixty 127\n",
      "numvisittotal 127\n",
      "numloggedinone 127\n",
      "numloggedinthreeone 127\n",
      "numloggedinseventhree 127\n",
      "numloggedinthirtyseven 127\n",
      "numloggedinsixtythirty 127\n",
      "numloggedinyearsixty 127\n",
      "numsecondsonsiteone 127\n",
      "numsecondsonsitethreeone 127\n",
      "numsecondsonsiteseventhree 127\n",
      "numsecondsonsitethirtyseven 127\n",
      "numsecondsonsitesixtythirty 127\n",
      "numsecondsonsiteyearsixty 127\n",
      "numtotalpageviewsone 127\n",
      "numtotalpageviewsthreeone 127\n",
      "numtotalpageviewsseventhree 127\n",
      "numtotalpageviewsthirtyseven 127\n",
      "numtotalpageviewssixtythirty 127\n",
      "numtotalpageviewsyearsixty 127\n",
      "numatcone 127\n",
      "numatcthreeone 127\n",
      "numatcseventhree 127\n",
      "numatcthirtyseven 127\n",
      "numatcsixtythirty 127\n",
      "numatcyearsixty 127\n",
      "numideaboardone 127\n",
      "numideaboardthreeone 127\n",
      "numideaboardseventhree 127\n",
      "numideaboardthirtyseven 127\n",
      "numideaboardsixtythirty 127\n",
      "numideaboardyearsixty 127\n",
      "sumatcprice 1594\n",
      "avgatcprice 1594\n",
      "numsearchtermsone 566\n",
      "numsearchtermsthreeone 566\n",
      "numsearchtermsseventhree 566\n",
      "numsearchtermsthirtyseven 566\n",
      "numsearchtermssixtythirty 566\n",
      "numsearchtermsyearsixty 566\n",
      "numskusviewedone 165\n",
      "numskusviewedthreeone 165\n",
      "numskusviewedseventhree 165\n",
      "numskusviewedthirtyseven 165\n",
      "numskusviewedsixtythirty 165\n",
      "numskusviewedyearsixty 165\n",
      "avgpriceone 2772\n",
      "avgpricethreeone 2455\n",
      "avgpriceseventhree 2044\n",
      "avgpricethirtyseven 889\n",
      "avgpricesixtythirty 1108\n",
      "avgpriceyearsixty 625\n",
      "avgprice 165\n",
      "numtasksfirstintroone 183\n",
      "numtasksfirstintrothreeone 183\n",
      "numtasksfirstintroseventhree 183\n",
      "numtasksfirstintrothirtyseven 183\n",
      "numtasksfirstintrosixtythirty 183\n",
      "numtasksfirstintroyearsixty 183\n",
      "numtaskscadenceone 183\n",
      "numtaskscadencethreeone 183\n",
      "numtaskscadenceseventhree 183\n",
      "numtaskscadencethirtyseven 183\n",
      "numtaskscadencesixtythirty 183\n",
      "numtaskscadenceyearsixty 183\n",
      "numtasksreassignone 183\n",
      "numtasksreassignthreeone 183\n",
      "numtasksreassignseventhree 183\n",
      "numtasksreassignthirtyseven 183\n",
      "numtasksreassignsixtythirty 183\n",
      "numtasksreassignyearsixty 183\n",
      "numtaskscustactone 183\n",
      "numtaskscustactthreeone 183\n",
      "numtaskscustactseventhree 183\n",
      "numtaskscustactthirtyseven 183\n",
      "numtaskscustactsixtythirty 183\n",
      "numtaskscustactyearsixty 183\n",
      "numtasksotherone 183\n",
      "numtasksotherthreeone 183\n",
      "numtasksotherseventhree 183\n",
      "numtasksotherthirtyseven 183\n",
      "numtasksothersixtythirty 183\n",
      "numtasksotheryearsixty 183\n",
      "numcallsone 183\n",
      "numcallsthreeone 183\n",
      "numcallsseventhree 183\n",
      "numcallsthirtyseven 183\n",
      "numcallssixtythirty 183\n",
      "numcallsyearsixty 183\n",
      "numemailsone 183\n",
      "numemailsthreeone 183\n",
      "numemailsseventhree 183\n",
      "numemailsthirtyseven 183\n",
      "numemailssixtythirty 183\n",
      "numemailsyearsixty 183\n",
      "totalcalldurationone 245\n",
      "totalcalldurationthreeone 221\n",
      "totalcalldurationseventhree 190\n",
      "totalcalldurationthirtyseven 218\n",
      "totalcalldurationsixtythirty 197\n",
      "totalcalldurationyearsixty 187\n",
      "decmakerflagone 183\n",
      "decmakerflagsevenone 183\n",
      "decmakerflagfourteenseven 183\n",
      "decmakerflagthirtyfourteen 183\n",
      "percsecondsinbound 1343\n",
      "percemailopenedone 48\n",
      "percemailopenedthreeone 48\n",
      "percemailopenedseventhree 48\n",
      "percemailopenedthirtyseven 48\n",
      "percemailopenedsixtythirty 48\n",
      "percemailopenedyearsixty 48\n",
      "percemailclickedone 48\n",
      "percemailclickedthreeone 48\n",
      "percemailclickedseventhree 48\n",
      "percemailclickedthirtyseven 48\n",
      "percemailclickedsixtythirty 48\n",
      "percemailclickedyearsixty 48\n",
      "currentapplicability 686\n",
      "numemaillist 686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre = Preprocessing()\n",
    "pre.dataImport('Training and Holdout Data/small.csv')\n",
    "\n",
    "pre.NanCounts()\n",
    "# pureMean, predictorSum, avgPredictorSum, populationAveragePredictor = pre.pureMean('revenue_30', True)\n",
    "\n",
    "# pre.NanCounts()\n",
    "\n",
    "# df = pre.getDf()\n",
    "# df.describe()\n",
    "# # df.unique()\n",
    "# df.groupby('numorderone').count()\n",
    "# df['numorderone'].value_counts(dropna = False)\n",
    "# s = df.iloc[:,22].value_counts(dropna = False)\n",
    "# # type(s.index[0])\n",
    "# print(s.get(float('nan')))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are columns with nans more or less likely to buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categories to continuous\n",
    "# Use dummy's, dict, or mean?\n",
    "\n",
    "# FUNCTIONS #\n",
    "\n",
    "# function for dummy's\n",
    "def preprocess_features(X):\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)\n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "        \n",
    "    return output\n",
    "\n",
    "# function for dict entire dataset\n",
    "def handle_non_numerical_data(df):\n",
    "    columns = df.columns.values\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "    return df\n",
    "\n",
    "# # function for dict individual column in dataset\n",
    "# def handle_non_numerical_data_individual(df_col, df):\n",
    "#     text_digit_vals = {}\n",
    "#     def convert_to_int(val):\n",
    "#         return text_digit_vals[val]\n",
    "#     if df_col.dtype != np.int64 and df_col.dtype != np.float64:\n",
    "#         column_contents = df_col.values.tolist()\n",
    "#         unique_elements = set(column_contents)\n",
    "# #         print(unique_elements)\n",
    "#         x = 0\n",
    "#         for unique in unique_elements:\n",
    "#             if unique not in text_digit_vals:\n",
    "#                 text_digit_vals[unique] = x\n",
    "#                 x+=1\n",
    "\n",
    "#         df_col = list(map(convert_to_int, df_col))\n",
    "#     print(text_digit_vals)\n",
    "#     return df_col\n",
    "\n",
    "def meanPreprocessor(df, colName, colComprRegr, colComprBin):\n",
    "    print(\"<< colName >>\")\n",
    "    print(colName)\n",
    "    print()\n",
    "    print(\"<< categories >>\")  \n",
    "    print(df[colName].unique())  # be careful of how it orders caregories  \n",
    "    print()\n",
    "    print(\"<< cat crosstab >>\")\n",
    "    print(pd.crosstab(df[colName], df[colComprBin]))\n",
    "    print()\n",
    "    print(\"<< cat totals >>\")\n",
    "    print(df[colName].value_counts())\n",
    "#     print(df[colName].value_counts(normalize=True))\n",
    "    print()\n",
    "    \n",
    "    print(\"<< cat total Revenues >>\")\n",
    "    revTotals = {}\n",
    "    for cat in range(len(df[colName].unique())): \n",
    "        revTotals[df[colName].unique()[cat]] = 0\n",
    "    print(revTotals)\n",
    "    \n",
    "    \n",
    "#     revTotals[\"Test\"]  = 0\n",
    "#     revTotals[\"Test2\"]  = 0\n",
    "#     revTotals[\"Test2\"]  = 4\n",
    "#     revTotals[\"Test3\"]  = [4]\n",
    "#     revTotals[\"Test3\"].append(0)\n",
    "\n",
    "#     print(df[colName].unique()[0])\n",
    "#     print(len(df))\n",
    "    for row in range(230):\n",
    "        if(df[colComprRegr][row]>0):\n",
    "            print(row, df[colComprRegr][row])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        revTotals[df[colName].unique()[cat]] = 0\n",
    "#     print(revTotals.rename_axis('1','2,','3'))\n",
    "#     for row in range(len(df)):\n",
    "        \n",
    "        \n",
    "    \n",
    "# print(dataframe_all['convert_30'].index.name)\n",
    "meanPreprocessor(dataframe_all, 'roll_up', 'revenue_30', 'convert_30')\n",
    "# dataframe_all\n",
    "# print(dataframe_all.groupby(['revenue_30', 'roll_up']).size().index[4])\n",
    "# print(dataframe_all.groupby(['revenue_30', 'roll_up']).size().index[4][0]>0)\n",
    "\n",
    "# X['numorderone']\n",
    "# dataframe_all['numorderone']\n",
    "\n",
    "# X['roll_up'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
